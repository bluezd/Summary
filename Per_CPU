void __init setup_per_cpu_areas(void)                       
{
        unsigned int cpu;
        unsigned long delta;
        int rc;         

        pr_info("NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%d nr_node_ids:%d\n",
                NR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);

        /*              
         * Allocate percpu area.  Embedding allocator is our favorite;
         * however, on NUMA configurations, it can result in very
         * sparse unit mapping and vmalloc area isn't spacious enough
         * on 32bit.  Use page in that case.                
         */             
#ifdef CONFIG_X86_32
        if (pcpu_chosen_fc == PCPU_FC_AUTO && pcpu_need_numa())
                pcpu_chosen_fc = PCPU_FC_PAGE;              
#endif      
        rc = -EINVAL;
        if (pcpu_chosen_fc != PCPU_FC_PAGE) {
                const size_t atom_size = cpu_has_pse ? PMD_SIZE : PAGE_SIZE;
                const size_t dyn_size = PERCPU_MODULE_RESERVE +
                        PERCPU_DYNAMIC_RESERVE - PERCPU_FIRST_CHUNK_RESERVE;

                rc = pcpu_embed_first_chunk(PERCPU_FIRST_CHUNK_RESERVE,
                                            dyn_size, atom_size,
                                            pcpu_cpu_distance,
                                            pcpu_fc_alloc, pcpu_fc_free);
                if (rc < 0)
                        pr_warning("PERCPU: %s allocator failed (%d), "
                                   "falling back to page size\n",
                                   pcpu_fc_names[pcpu_chosen_fc], rc);
        }
        if (rc < 0)
                rc = pcpu_page_first_chunk(PERCPU_FIRST_CHUNK_RESERVE,
                                           pcpu_fc_alloc, pcpu_fc_free,
                                           pcpup_populate_pte);
        if (rc < 0)
                panic("cannot initialize percpu area (err=%d)", rc);

        /* alrighty, percpu areas up and running */
        delta = (unsigned long)pcpu_base_addr - (unsigned long)__per_cpu_start;
        for_each_possible_cpu(cpu) {
                per_cpu_offset(cpu) = delta + pcpu_unit_offsets[cpu];
                per_cpu(this_cpu_off, cpu) = per_cpu_offset(cpu);
                per_cpu(cpu_number, cpu) = cpu;
                setup_percpu_segment(cpu);
                setup_stack_canary_segment(cpu);
                /*
                 * Copy data used in early init routines from the
                 * initial arrays to the per cpu data areas.  These
                 * arrays then become expendable and the *_early_ptr's
                 * are zeroed indicating that the static arrays are
                 * gone.
                 */
#ifdef CONFIG_X86_LOCAL_APIC
                per_cpu(x86_cpu_to_apicid, cpu) =
                        early_per_cpu_map(x86_cpu_to_apicid, cpu);
                per_cpu(x86_bios_cpu_apicid, cpu) =
                        early_per_cpu_map(x86_bios_cpu_apicid, cpu);
#endif
#ifdef CONFIG_X86_64
                per_cpu(irq_stack_ptr, cpu) =
                        per_cpu(irq_stack_union.irq_stack, cpu) +
                        IRQ_STACK_SIZE - 64;
#ifdef CONFIG_NUMA
                per_cpu(x86_cpu_to_node_map, cpu) =
                        early_per_cpu_map(x86_cpu_to_node_map, cpu);
#endif
#endif
                /*
                 * Up to this point, the boot CPU has been using .data.init
                 * area.  Reload any changed state for the boot CPU.
                 */
                if (cpu == boot_cpu_id)
                        switch_to_new_gdt(cpu);
        }

        /* indicate the early static arrays will soon be gone */
#ifdef CONFIG_X86_LOCAL_APIC
        early_per_cpu_ptr(x86_cpu_to_apicid) = NULL;
        early_per_cpu_ptr(x86_bios_cpu_apicid) = NULL;
#endif
#if defined(CONFIG_X86_64) && defined(CONFIG_NUMA)
        early_per_cpu_ptr(x86_cpu_to_node_map) = NULL;
#endif

#if defined(CONFIG_X86_64) && defined(CONFIG_NUMA)
        /*
         * make sure boot cpu node_number is right, when boot cpu is on the
         * node that doesn't have mem installed
         */
        per_cpu(node_number, boot_cpu_id) = cpu_to_node(boot_cpu_id);
#endif

        /* Setup node to cpumask map */
        setup_node_to_cpumask_map();

        /* Setup cpu initialized, callin, callout masks */
        setup_cpu_local_masks();
}

smp_processor_id()

# define smp_processor_id() raw_smp_processor_id()

CONFIG_X86_64_SMP
CONFIG_X86_32_SMP

#define raw_smp_processor_id() (percpu_read(cpu_number))

#define percpu_read(var)	percpu_from_op("mov", per_cpu__##var,	\
					       "m" (per_cpu__##var))

#define percpu_from_op(op, var, constraint)             \
({                                                      \
        typeof(var) ret__;                              \
        switch (sizeof(var)) {                          \
        case 1:                                         \
                asm(op "b "__percpu_arg(1)",%0"         \
                    : "=q" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 2:                                         \
                asm(op "w "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 4:                                         \
                asm(op "l "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 8:                                         \
                asm(op "q "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        default: __bad_percpu_size();                   \
        }                                               \
        ret__;                                          \
})

#define __percpu_arg(x)		"%%"__stringify(__percpu_seg)":%P" #x

asm("movb %%fs:%P1, %0"
	:"=q"(ret__)
	:"m"(per_cpu__cpu_number));

---------------------------------------------------------------------------------------------------------------------------------------------------------------------

DEFINE_PER_CPU(struct hrtimer_cpu_base, hrtimer_bases) =
{       
        
        .clock_base =
        {       
                {       
                        .index = CLOCK_REALTIME,
                        .get_time = &ktime_get_real,
                        .resolution = KTIME_LOW_RES,
                },
                {       
                        .index = CLOCK_MONOTONIC,
                        .get_time = &ktime_get,
                        .resolution = KTIME_LOW_RES,
                },
        }
};


#define DEFINE_PER_CPU(type, name)                                      \
        DEFINE_PER_CPU_SECTION(type, name, "")

#define DEFINE_PER_CPU_SECTION(type, name, sec)                         \
        __PCPU_ATTRS(sec) PER_CPU_DEF_ATTRIBUTES                        \
        __typeof__(type) per_cpu__##name


#define __PCPU_ATTRS(sec)                                               \
        __attribute__((section(PER_CPU_BASE_SECTION sec)))              \
        PER_CPU_ATTRIBUTES
        // NULL

#define PER_CPU_BASE_SECTION ".data.percpu"

// __attribute__((section(.data.percpu "")

DEFINE_PER_CPU(struct hrtimer_cpu_base, hrtimer_bases)

:
__attribute__((section(.data.percpu))) __typeof__(hrtimer_cpu_base) per_cpu__hrtimer_bases
// 在 .data section 定义一个变量 per_cpu__hrtimer_bases 类型为 struct hrtimer_cpu_base





-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

cpu_base = &__raw_get_cpu_var(hrtimer_bases);

#define __raw_get_cpu_var(var) \
	        (*SHIFT_PERCPU_PTR(&per_cpu_var(var), __my_cpu_offset))

#define per_cpu_var(var) per_cpu__##var   // per_cpu_hrtimer_bases

#define SHIFT_PERCPU_PTR(__p, __offset) RELOC_HIDE((__p), (__offset))

#define __my_cpu_offset per_cpu_offset(raw_smp_processor_id())


extern unsigned long __per_cpu_offset[NR_CPUS];

#define per_cpu_offset(x) (__per_cpu_offset[x])

unsigned long __per_cpu_offset[NR_CPUS] __read_mostly = {
	        [0 ... NR_CPUS-1] = BOOT_PERCPU_OFFSET,
};
EXPORT_SYMBOL(__per_cpu_offset);

初始化在 setup_per_cpu_areas() 

#define BOOT_PERCPU_OFFSET ((unsigned long)__per_cpu_load)


 +-------------------------------------------------------------------------------------+
 |      arch/x86/kernel/vmlinux.lds.S                                                  |
 |      /*                                                                             |
 |       *  * Per-cpu symbols which need to be offset from __per_cpu_load              |
 |       *   * for the boot processor.                                                 |
 |       *    */                                                                       |
 |      #define INIT_PER_CPU(x) init_per_cpu__##x = per_cpu__##x + __per_cpu_load      |
 |      INIT_PER_CPU(gdt_page);                                                        |
 |      INIT_PER_CPU(irq_stack_union);                                                 |
 |                                                                                     |
 +-------------------------------------------------------------------------------------+
 
#define __raw_get_cpu_var(var) \
	 (*SHIFT_PERCPU_PTR(&per_cpu_hrtimer_bases, __per_cpu_offset[CURRENT_CPU_NUMBER]))

=> RELOC_HIDE((&per_cpu_hrtimer_bases),(__per_cpu_offset[CURRENT_CPU_NUMBER]))

# define RELOC_HIDE(ptr, off)                                   \
  ({ unsigned long __ptr;                                       \
     __ptr = (unsigned long) (ptr);                             \
    (typeof(ptr)) (__ptr + (off)); })

*((struct hrtimer_cpu_base) (&per_cpu_hrtimer_bases + __per_cpu_offset[CURRENT_CPU_NUMBER]))

// 这样就获得了 cpu X 的 per cpu 变量 per_cpu_hrtimer_bases 。

__per_cpu_offset 保存的是 per cpu 变量的本地拷贝和 .data.percpu 段的地址的差值。


#define percpu_read(var)        percpu_from_op("mov", per_cpu__##var,   \
                                               "m" (per_cpu__##var))

#define percpu_from_op(op, var, constraint)             \
({                                                      \
        typeof(var) ret__;                              \
        switch (sizeof(var)) {                          \
        case 1:                                         \
                asm(op "b "__percpu_arg(1)",%0"         \
                    : "=q" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 2:                                         \
                asm(op "w "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 4:                                         \
                asm(op "l "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        case 8:                                         \
                asm(op "q "__percpu_arg(1)",%0"         \
                    : "=r" (ret__)                      \
                    : constraint);                      \
                break;                                  \
        default: __bad_percpu_size();                   \
        }                                               \
        ret__;                                          \
})


asm("movb "__percpu_arg(1)",%0"        
     : "=q" (pfo_ret__)                  
     : constraint);

#define __percpu_arg(x)         "%%"__stringify(__percpu_seg)":%P" #x

#ifdef CONFIG_X86_64
#define __percpu_seg            gs
#define __percpu_mov_op         movq
#else
#define __percpu_seg            fs
#define __percpu_mov_op         movl
#endif

所以__percpu_arg(x)翻译过来就是：
"%%"__stringify(gs)":%P" #x

"%%"__stringify(gs)":%P" "1"

最终宏  __percpu_arg() "%%" "gs:%P" "1"


asm("movb %%gs:%P1, %0"
        :"=q"(ret__)
        :"m"(per_cpu__cpu_number));

