current nfs/fscache only support * write-through * caching based on fscache/cachefiles (two kernel modules) 

IDEA: so the goal is making NFS support * write-back * cache. Modify the nfs/fscache/cachefiles

The type of Cache
    --Write Through
        当写数据进Cache时，也同时更新了相应的Memory里的内容
    --Write back
	只是写到Cache里，Memory 的内容要等到 cache 保存的要被别的数据替换或者系统做cache flush时，才会被更新。


With wider adoption of SSD on nfs client side, it would be great for nfs to support writeback cache to speed up write intensive clients.
flashcache/bcache only works for local filesystems. 

B-cache: which is a Linux kernel module intended to improve the performance of block devices. Instead of using just memory to cache hard drives, he proposes to use one or more solid-state storage devices (SSDs) to cache block data (hence bcache, a block device cache). 

// When data is read from the hard drive, a copy is saved to the SSD. Later, when one of those sectors needs to be retrieved again, the kernel checks to see if it's still in page cache(RAM). If so, the read comes from RAM just like it always has on Linux. If it's not in RAM but it is on the SSD, it's read from there. It's like we've added 64GB or more of - slower - RAM to the system and devoted it to caching.

Note that this type of caching is only for block devices (anything that shows up as a block device in /dev/). It isn't for network filesystems like NFS, CIFS, and so on

/* fscache 的出现就是为了实现和 bcache 类似的功能 */



FS-Cache mediates between cache backends (such as CacheFS) and network
filesystems:
       
        +---------+
        |         |                        +--------------+
        |   NFS   |--+                     |              |
        |         |  |                 +-->|   CacheFS    |
        +---------+  |   +----------+  |   |  /dev/hda5   |
                     |   |          |  |   +--------------+
        +---------+  +-->|          |  |
        |         |      |          |--+
        |   AFS   |----->| FS-Cache |
        |         |      |          |--+
        +---------+  +-->|          |  |
                     |   |          |  |   +--------------+
        +---------+  |   +----------+  |   |              |
        |         |  |                 +-->|  CacheFiles  |
        |  ISOFS  |--+                     |  /var/cache  |
        |         |                        +--------------+
        +---------+

          netfs           fscache              backend

Fs-Cache has two set of APIs
 1. front-end --> nfs use it
 2. back-end  --> the implementation of write through method of FS-cache
                                        write back

FS-Cache 是指在文件系统和缓存之间的接口。
CacheFS 指的则是FS-cache的缓存后端
        -> CacheFS做实际的数据存储和检索处理，并使用块设备的分区。

# mount -o fsc server:/export /mnt/export





------------------------------------------------------ 8< -----------------------------------------------------------------------------------------------------
The netfs and FS-Cache talk to each other by means of cookies. These are elements of the virtual indexing tree that FS-Cache maintains,but they appear as opaque pointers to the netfs.
They are of type:
struct fscache_cookie *

fs_initcall(fscache_init);    // 5
syslog:
FS-Cache: Loaded

/*
 * initialise the fs caching module
 */
static int __init fscache_init(void)
{
        int ret;

        ret = slow_work_register_user(THIS_MODULE);
        if (ret < 0)
                goto error_slow_work;

        ret = fscache_proc_init();
        if (ret < 0)
                goto error_proc;

        fscache_cookie_jar = kmem_cache_create("fscache_cookie_jar",
                                               sizeof(struct fscache_cookie),
                                               0,
                                               0,
                                               fscache_cookie_init_once);
	// 创建一个高速缓存描述符 slab
	
        if (!fscache_cookie_jar) {
                printk(KERN_NOTICE
                       "FS-Cache: Failed to allocate a cookie jar\n");
                ret = -ENOMEM;
                goto error_cookie_jar;
        }
        
        fscache_root = kobject_create_and_add("fscache", kernel_kobj);
        if (!fscache_root)
                goto error_kobj;

        printk(KERN_NOTICE "FS-Cache: Loaded\n");
        return 0;

error_kobj:
        kmem_cache_destroy(fscache_cookie_jar);
error_cookie_jar:
        fscache_proc_cleanup();
error_proc:
        slow_work_unregister_user(THIS_MODULE);
error_slow_work:
        return ret;
}


A netfs receives a cookie from FS-Cache when it registers. This cookie represents the primary index of this netfs. A netfs can acquire fur-ther cookies by asking FS-Cache to perform a lookup in an object represented by a cookie it already has.


module_init(init_nfs_fs)      // 6

/*
 * Initialize NFS
 */
static int __init init_nfs_fs(void)
{
        int err;

        err = nfs_idmap_init();
        if (err < 0)
                goto out9;

        err = nfs_dns_resolver_init();
        if (err < 0)
                goto out8;

        err = nfs_fscache_register();
        if (err < 0)
                goto out7;
        // fscache register

        err = nfsiod_start();
        if (err)
                goto out6;

        err = nfs_fs_proc_init();
        if (err)
                goto out5;

        err = nfs_init_nfspagecache();
        if (err)
                goto out4;

        err = nfs_init_inodecache();
        if (err)
                goto out3;

        err = nfs_init_readpagecache();
        if (err)
                goto out2;

        err = nfs_init_writepagecache();
        if (err)
                goto out1;

        err = nfs_init_directcache();
        if (err)
                goto out0;

#ifdef CONFIG_PROC_FS
        rpc_proc_register(&nfs_rpcstat);
#endif
        if ((err = register_nfs_fs()) != 0)
                goto out;
        return 0;
out:
#ifdef CONFIG_PROC_FS
        rpc_proc_unregister("nfs");
#endif
        nfs_destroy_directcache();
out0:
        nfs_destroy_writepagecache();
out1:
        nfs_destroy_readpagecache();
out2:
        nfs_destroy_inodecache();
out3:
        nfs_destroy_nfspagecache();
out4:
        nfs_fs_proc_exit();
out5:
        nfsiod_stop();
out6:
        nfs_fscache_unregister();
out7:
        nfs_dns_resolver_destroy();
out8:
        nfs_idmap_quit();
out9:
        return err;
}

/*
 * Register NFS for caching
 */
int nfs_fscache_register(void)
{
        return fscache_register_netfs(&nfs_fscache_netfs);
}


/*
 * fscache cached network filesystem type
 * - name, version and ops must be filled in before registration
 * - all other fields will be set during registration
 */
struct fscache_netfs {
        uint32_t                        version;        /* indexing version */
        const char                      *name;          /* filesystem name */
        struct fscache_cookie           *primary_index;
        struct list_head                link;           /* internal link */
};


 +------------------------------------------------------------------------------------------+
 |      /*                                                                                  |
 |       * Define the NFS filesystem for FS-Cache.  Upon registration FS-Cache sticks       |
 |       * the cookie for the top-level index object for NFS into here.  The top-level      |
 |       * index can than have other cache objects inserted into it.                        |
 |       */                                                                                 |
 |      struct fscache_netfs nfs_fscache_netfs = {                                          |
 |      	.name           = "nfs",                                                    |
 |      	.version        = 0,                                                        |
 |      };                                                                                  |
 +------------------------------------------------------------------------------------------+

/**
 * fscache_register_netfs - Register a filesystem as desiring caching services
 * @netfs: The description of the filesystem
 *
 * Register a filesystem as desiring caching services if they're available.
 *
 * See Documentation/filesystems/caching/netfs-api.txt for a complete
 * description.
 */
static inline
int fscache_register_netfs(struct fscache_netfs *netfs)
{
        if (fscache_available())
                return __fscache_register_netfs(netfs);
        else
                return 0;
}
#if defined(CONFIG_FSCACHE) || defined(CONFIG_FSCACHE_MODULE)
#define fscache_available() (1)
#endif

/*
 * register a network filesystem for caching
 */
int __fscache_register_netfs(struct fscache_netfs *netfs)
{
        struct fscache_netfs *ptr;
        int ret;

        _enter("{%s}", netfs->name);

        INIT_LIST_HEAD(&netfs->link);

        /* allocate a cookie for the primary index */
        netfs->primary_index =
                kmem_cache_zalloc(fscache_cookie_jar, GFP_KERNEL);
        // 从 fscache_cookie_jar 高速缓存描述符中分配一个 struct fscache_cookie 结构  
        // The netfs and FS-Cache talk to each other by means of cookies These are elements of the virtual indexing tree that FS-Cache maintains
	// specifying the layout of the primary index


        if (!netfs->primary_index) {
                _leave(" = -ENOMEM");
                return -ENOMEM;
        }

        /* initialise the primary index cookie */
        atomic_set(&netfs->primary_index->usage, 1);
        atomic_set(&netfs->primary_index->n_children, 0);

        netfs->primary_index->def               = &fscache_fsdef_netfs_def;
        netfs->primary_index->parent            = &fscache_fsdef_index;
        netfs->primary_index->netfs_data        = netfs;

        atomic_inc(&netfs->primary_index->parent->usage);
        atomic_inc(&netfs->primary_index->parent->n_children);

        spin_lock_init(&netfs->primary_index->lock);
        INIT_HLIST_HEAD(&netfs->primary_index->backing_objects);

        /* check the netfs type is not already present */
        down_write(&fscache_addremove_sem);

        ret = -EEXIST;
        list_for_each_entry(ptr, &fscache_netfs_list, link) {
                if (strcmp(ptr->name, netfs->name) == 0)
                        goto already_registered;
        }

        list_add(&netfs->link, &fscache_netfs_list);
        ret = 0;

        printk(KERN_NOTICE "FS-Cache: Netfs '%s' registered for caching\n",
               netfs->name);

already_registered:
        up_write(&fscache_addremove_sem);

        if (ret < 0) {
                netfs->primary_index->parent = NULL;
                __fscache_cookie_put(netfs->primary_index);
                netfs->primary_index = NULL;
        }

        _leave(" = %d", ret);
        return ret;
}

backend-api: This API is declared in <linux/fscache-cache.h>
front-api:                           <linux/fscache.h>

Note:
当 client 端读取一个文件的时候，nfs 会调用 fscache 的 API 实现缓存操作，缓存到 /var/cache/fscache/cache 下
当 client 写一个文件时，不会发生缓存操作。

当 client 挂在 server export 出的目录到本地时(假设挂载到 /mnt下)，那此时在本地 ll /mnt 显示的内容（目录和文件的信息dentry and inode）都应该保存在本地的内存中（相应的结构中），并且如果在 client 端读取 server 端的一个文件时，对应该文件的内容会被 nfs 缓存到内存中，也同时会被 fscache 缓存到本地。

当 client 挂载 server export 出的目录到本地时(假设挂载到本地的 /mnt下)，那此时在本地 ll /mnt 显示的内容（目录和文件的信息dentry and inode）都应该保存在本地的内存中（相应的结构中），并且如果在 client 端读取 server 端的一个文件时，对应该文件的内容会被 nfs 缓存到内存中，也同时会被 fscache 缓存到本地.

当 client 端读取一个文件的时候，nfs 会调用 fscache 的 API 实现缓存操作，缓存到 /var/cache/fscache/cache 下，当只有读取文件时才会 fscache 到本地，当 client 写一个文件时根本就不会 fscache 到本地.(文件写打开的时候cache就失效了,文件可写打开时候nfs会主动失效cache).



-------------------------------------------------------- 8< ---------------------------------------------------------------------------------------------------
NFS 挂载大致过程:

fs/namespace.c:
SYSCALL_DEFINE5(mount, char __user *, dev_name, char __user *, dir_name,char __user *, type, unsigned long, flags, void __user *, data)
  -> do_mount()
      -> do_new_mount()
	  -> do_kern_mount()


struct vfsmount *
do_kern_mount(const char *fstype, int flags, const char *name, void *data)
{
        struct file_system_type *type = get_fs_type(fstype);
        // 文件系统类型 nfs_fs_type  

        struct vfsmount *mnt;
        if (!type)
                return ERR_PTR(-ENODEV);
        mnt = vfs_kern_mount(type, flags, name, data);
        if (!IS_ERR(mnt) && (type->fs_flags & FS_HAS_SUBTYPE) &&
            !mnt->mnt_sb->s_subtype)
                mnt = fs_set_subtype(mnt, fstype);
        put_filesystem(type);
        return mnt;
}

static struct file_system_type nfs_fs_type = {
        .owner          = THIS_MODULE,
        .name           = "nfs",
        .get_sb         = nfs_get_sb,
        .kill_sb        = nfs_kill_super,
        .fs_flags       = FS_RENAME_DOES_D_MOVE|FS_REVAL_DOT|FS_BINARY_MOUNTDATA,
};

struct vfsmount *
vfs_kern_mount(struct file_system_type *type, int flags, const char *name, void *data)
{
        struct vfsmount *mnt;
        char *secdata = NULL;
        int error;

        if (!type)
                return ERR_PTR(-ENODEV);

        error = -ENOMEM;
        mnt = alloc_vfsmnt(name);
        // 创建一个 struct vfsmount 结构 以挂载文件系统描述符

        if (!mnt)
                goto out;

        if (data && !(type->fs_flags & FS_BINARY_MOUNTDATA)) {
                secdata = alloc_secdata();
                if (!secdata)
                        goto out_mnt;

                error = security_sb_copy_data(data, secdata);
                if (error)
                        goto out_free_secdata;
        }

        error = type->get_sb(type, flags, name, data, mnt);
        // Get SB 
        // inovke the nfs_get_sb()

        if (error < 0)
                goto out_free_secdata;
        BUG_ON(!mnt->mnt_sb);

        error = security_sb_kern_mount(mnt->mnt_sb, flags, secdata);
        if (error)
                goto out_sb;

        /*
         * filesystems should never set s_maxbytes larger than MAX_LFS_FILESIZE
         * but s_maxbytes was an unsigned long long for many releases. Throw
         * this warning for a little while to try and catch filesystems that
         * violate this rule. This warning should be either removed or
         * converted to a BUG() in 2.6.34.
         */
        WARN((mnt->mnt_sb->s_maxbytes < 0), "%s set sb->s_maxbytes to "
                "negative value (%lld)\n", type->name, mnt->mnt_sb->s_maxbytes);

        mnt->mnt_mountpoint = mnt->mnt_root;
	// mnt_mountpoint 指向这个文件系统安装点目录的 dentry
	
        mnt->mnt_parent = mnt;
	// 父文件系统，这个文件系统安装其上
	
        up_write(&mnt->mnt_sb->s_umount);
        free_secdata(secdata);
        return mnt;
out_sb:
        dput(mnt->mnt_root);
        deactivate_locked_super(mnt->mnt_sb);
out_free_secdata:
        free_secdata(secdata);
out_mnt:
        free_vfsmnt(mnt);
out:
        return ERR_PTR(error);
}

static int nfs_get_sb(struct file_system_type *fs_type,
        int flags, const char *dev_name, void *raw_data, struct vfsmount *mnt)
{
        struct nfs_server *server = NULL;
        struct super_block *s;
        struct nfs_parsed_mount_data *data;
        struct nfs_fh *mntfh;
        struct dentry *mntroot;
        int (*compare_super)(struct super_block *, void *) = nfs_compare_super;
        struct nfs_sb_mountdata sb_mntdata = {
                .mntflags = flags,
        };
        int error = -ENOMEM;

        data = nfs_alloc_parsed_mount_data(NFS_DEFAULT_VERSION);
        // 创建一个 nfs_parsed_mount_data (In-kernel mount arguments)
	// 默认版本 v3

        mntfh = nfs_alloc_fhandle();
        // 创建一个 client file handle

        if (data == NULL || mntfh == NULL)
                goto out_free_fh;

        security_init_mnt_opts(&data->lsm_opts);

        /* Validate the mount data */
        error = nfs_validate_mount_data(raw_data, data, mntfh, dev_name);
        if (error < 0)
                goto out;

#ifdef CONFIG_NFS_V4
        if (data->version == 4) {
                error = nfs4_try_mount(flags, dev_name, data, mnt);
                kfree(data->client_address);
                kfree(data->nfs_server.export_path);
                goto out;
        }
#endif  /* CONFIG_NFS_V4 */

        /* Get a volume representation */
        server = nfs_create_server(data, mntfh);
        // 创建 struct nfs_server 结构 

        if (IS_ERR(server)) {
                error = PTR_ERR(server);
                goto out;
        }
        sb_mntdata.server = server;

        if (server->flags & NFS_MOUNT_UNSHARED)
                compare_super = NULL;

        /* -o noac implies -o sync */
        if (server->flags & NFS_MOUNT_NOAC)
                sb_mntdata.mntflags |= MS_SYNCHRONOUS;

        /* Get a superblock - note that we may end up sharing one that already exists */
        s = sget(fs_type, compare_super, nfs_set_super, &sb_mntdata);
        // 获得超级块

        if (IS_ERR(s)) {
                error = PTR_ERR(s);
                goto out_err_nosb;
        }

        if (s->s_fs_info != server) {
                nfs_free_server(server);
                server = NULL;
        } else {
                error = nfs_bdi_register(server);
                if (error)
                        goto error_splat_bdi;
        }

        if (!s->s_root) {
        // struct superblock 结构中 struct dentry  *s_root
        // 文件系统根目录的目录项对象(此时为空)

                /* initial superblock/root creation */
                nfs_fill_super(s, data);
                nfs_fscache_get_super_cookie(
                        s, data ? data->fscache_uniq : NULL, NULL);
        }

        mntroot = nfs_get_root(s, mntfh);
        // Get the get an NFS2/NFS3 root dentry from the root filehandle 
        if (IS_ERR(mntroot)) {
                error = PTR_ERR(mntroot);
                goto error_splat_super;
        }

        error = security_sb_set_mnt_opts(s, &data->lsm_opts);
        if (error)
                goto error_splat_root;

        s->s_flags |= MS_ACTIVE;
        mnt->mnt_sb = s;
        // 指向 superblock
        mnt->mnt_root = mntroot;
        // root dentry 

        error = 0;

out:
        kfree(data->nfs_server.hostname);
        kfree(data->mount_server.hostname);
        kfree(data->fscache_uniq);
        security_free_mnt_opts(&data->lsm_opts);
out_free_fh:
        nfs_free_fhandle(mntfh);
        kfree(data);
        return error;

out_err_nosb:
        nfs_free_server(server);
        goto out;

error_splat_root:
        dput(mntroot);
error_splat_super:
        if (server && !s->s_root)
                bdi_unregister(&server->backing_dev_info);
error_splat_bdi:
        deactivate_locked_super(s);
        goto out;
}

struct nfs_fh *nfs_alloc_fhandle(void)
{       
        struct nfs_fh *fh;
        
        fh = kmalloc(sizeof(struct nfs_fh), GFP_NOFS);
        if (fh != NULL)
                fh->size = 0;
        return fh;
}       

/*
 * This is the kernel NFS client file handle representation
 */
#define NFS_MAXFHSIZE           128
struct nfs_fh {
        unsigned short          size;
        unsigned char           data[NFS_MAXFHSIZE];
};

fs/super.c
/**
 *      sget    -       find or create a superblock
 *      @type:  filesystem type superblock should belong to
 *      @test:  comparison callback
 *      @set:   setup callback
 *      @data:  argument to each of them
 */
struct super_block *sget(struct file_system_type *type,
                        int (*test)(struct super_block *,void *),
                        int (*set)(struct super_block *,void *),
                        void *data)
{      
        struct super_block *s = NULL;
        struct super_block *old;
        int err;

retry: 
        spin_lock(&sb_lock);
        if (test) {
        // compare_super()
                list_for_each_entry(old, &type->fs_supers, s_instances) {
                // struct file_system_type 结构中 struct list_head fs_supers 字段表示具有相同文件系统类型的超级块对象链表的头
 
                        if (!test(old, data))
                                continue;
                        if (!grab_super(old))
                                goto retry;
                        if (s) {
                                up_write(&s->s_umount);
                                destroy_super(s);
                        }
                        return old;
                }
        }
        if (!s) {
                spin_unlock(&sb_lock);
                s = alloc_super(type);
                // 创建一个 super block

                if (!s)
                        return ERR_PTR(-ENOMEM);
                goto retry;
        }
       
        err = set(s, data);
        //nfs_set_super ()  data = &sb_mntdata

        if (err) {
                spin_unlock(&sb_lock);
                up_write(&s->s_umount);
                destroy_super(s);
                return ERR_PTR(err);
        }
        s->s_type = type;
        strlcpy(s->s_id, type->name, sizeof(s->s_id));
        list_add_tail(&s->s_list, &super_blocks);
        // 把此超级块加入到全局链表(super_blocks)中

        list_add(&s->s_instances, &type->fs_supers);
        // 将超级块加入到文件系统链表中

        spin_unlock(&sb_lock);
        get_filesystem(type);
        return s;
}

struct nfs_sb_mountdata {
        struct nfs_server *server;
        int mntflags;
};

static int nfs_set_super(struct super_block *s, void *data)
{
        struct nfs_sb_mountdata *sb_mntdata = data;
        struct nfs_server *server = sb_mntdata->server;
        int ret;

        s->s_flags = sb_mntdata->mntflags;
        s->s_fs_info = server;
        ret = set_anon_super(s, server);
        if (ret == 0)
                server->s_dev = s->s_dev;
        return ret;
}

/*
 * Finish setting up an NFS2/3 superblock
 */
static void nfs_fill_super(struct super_block *sb,
                           struct nfs_parsed_mount_data *data)
{
        struct nfs_server *server = NFS_SB(sb);
        // 获得 super block 结构中的 s->s_fs_info 指向的 struct nfs_server 结构 

        sb->s_blocksize_bits = 0;
        sb->s_blocksize = 0;
        if (data->bsize)
                sb->s_blocksize = nfs_block_size(data->bsize, &sb->s_blocksize_bits);

        if (server->nfs_client->rpc_ops->version == 3) {
                /* The VFS shouldn't apply the umask to mode bits. We will do
                 * so ourselves when necessary.
                 */
                sb->s_flags |= MS_POSIXACL;
                sb->s_time_gran = 1;
        }

        sb->s_op = &nfs_sops;
        nfs_initialise_sb(sb);
}

static inline struct nfs_server *NFS_SB(const struct super_block *s)
{
        return (struct nfs_server *)(s->s_fs_info);
}

/*
 * Initialise the common bits of the superblock
 */
static inline void nfs_initialise_sb(struct super_block *sb)
{
        struct nfs_server *server = NFS_SB(sb);

        sb->s_magic = NFS_SUPER_MAGIC;

        /* We probably want something more informative here */
        snprintf(sb->s_id, sizeof(sb->s_id),
                 "%x:%x", MAJOR(sb->s_dev), MINOR(sb->s_dev));

        if (sb->s_blocksize == 0)
                sb->s_blocksize = nfs_block_bits(server->wsize,
                                                 &sb->s_blocksize_bits);

        sb->s_bdi = &server->backing_dev_info;

        nfs_super_set_maxbytes(sb, server->maxfilesize);
}

/*
 * Get the cache cookie for an NFS superblock.  We have to handle
 * uniquification here because the cache doesn't do it for us.
 *
 * The default uniquifier is just an empty string, but it may be overridden
 * either by the 'fsc=xxx' option to mount, or by inheriting it from the parent
 * superblock across an automount point of some nature.
 */
void nfs_fscache_get_super_cookie(struct super_block *sb, const char *uniq,
                                  struct nfs_clone_mount *mntdata)
{
        // mntdata = NULL

        struct nfs_fscache_key *key, *xkey;
        struct nfs_server *nfss = NFS_SB(sb);
        struct rb_node **p, *parent;
        int diff, ulen;

        if (uniq) {
                ulen = strlen(uniq);
        } else if (mntdata) {
                struct nfs_server *mnt_s = NFS_SB(mntdata->sb);
                if (mnt_s->fscache_key) {
                        uniq = mnt_s->fscache_key->key.uniquifier;
                        ulen = mnt_s->fscache_key->key.uniq_len;
                }
        }

        if (!uniq) {
                uniq = "";
                ulen = 1;
        }

        key = kzalloc(sizeof(*key) + ulen, GFP_KERNEL);
        if (!key)
                return;

        key->nfs_client = nfss->nfs_client;
        key->key.super.s_flags = sb->s_flags & NFS_MS_MASK;
        key->key.nfs_server.flags = nfss->flags;
        key->key.nfs_server.rsize = nfss->rsize;
        key->key.nfs_server.wsize = nfss->wsize;
        key->key.nfs_server.acregmin = nfss->acregmin;
        key->key.nfs_server.acregmax = nfss->acregmax;
        key->key.nfs_server.acdirmin = nfss->acdirmin;
        key->key.nfs_server.acdirmax = nfss->acdirmax;
        key->key.nfs_server.fsid = nfss->fsid;
        key->key.rpc_auth.au_flavor = nfss->client->cl_auth->au_flavor;

        key->key.uniq_len = ulen;
        memcpy(key->key.uniquifier, uniq, ulen);

        spin_lock(&nfs_fscache_keys_lock);
        p = &nfs_fscache_keys.rb_node;
        parent = NULL;
        while (*p) {
                parent = *p;
                xkey = rb_entry(parent, struct nfs_fscache_key, node);

                if (key->nfs_client < xkey->nfs_client)
                        goto go_left;
                if (key->nfs_client > xkey->nfs_client)
                        goto go_right;

                diff = memcmp(&key->key, &xkey->key, sizeof(key->key));
                if (diff < 0)
                        goto go_left;
                if (diff > 0)
                        goto go_right;

                if (key->key.uniq_len == 0)
                        goto non_unique;
                diff = memcmp(key->key.uniquifier,
                              xkey->key.uniquifier,
                              key->key.uniq_len);
                if (diff < 0)
                        goto go_left;
                if (diff > 0)
                        goto go_right;
                goto non_unique;

        go_left:
                p = &(*p)->rb_left;
                continue;
        go_right:
                p = &(*p)->rb_right;
        }

        rb_link_node(&key->node, parent, p);
        rb_insert_color(&key->node, &nfs_fscache_keys);
        spin_unlock(&nfs_fscache_keys_lock);
        nfss->fscache_key = key;

        /* create a cache index for looking up filehandles */
        nfss->fscache = fscache_acquire_cookie(nfss->nfs_client->fscache,
                                               &nfs_fscache_super_index_def,
                                               nfss);
        // struct nfs_server 结构中 struct fscache_cookie   *fscache;       /* superblock cookie */ 
        dfprintk(FSCACHE, "NFS: get superblock cookie (0x%p/0x%p)\n",
                 nfss, nfss->fscache);
        return;

non_unique:
        spin_unlock(&nfs_fscache_keys_lock);
        kfree(key);
        nfss->fscache_key = NULL;
        nfss->fscache = NULL;
        printk(KERN_WARNING "NFS:"
               " Cache request denied due to non-unique superblock keys\n");
}

/*      
 * Define the superblock object for FS-Cache.  This is used to describe a
 * superblock object to fscache_acquire_cookie().  It is keyed by all the NFS
 * parameters that might cause a separate superblock.
 */
const struct fscache_cookie_def nfs_fscache_super_index_def = {
        .name           = "NFS.super",
        .type           = FSCACHE_COOKIE_TYPE_INDEX,
        .get_key        = nfs_super_get_key,
};      

/**             
 * fscache_acquire_cookie - Acquire a cookie to represent a cache object
 * @parent: The cookie that's to be the parent of this one
 * @def: A description of the cache object, including callback operations
 * @netfs_data: An arbitrary piece of data to be kept in the cookie to
 * represent the cache object to the netfs
 *      
 * This function is used to inform FS-Cache about part of an index hierarchy
 * that can be used to locate files.  This is done by requesting a cookie for
 * each index in the path to the file.
 *      
 * See Documentation/filesystems/caching/netfs-api.txt for a complete
 * description.
 */     
static inline
struct fscache_cookie *fscache_acquire_cookie( 
        struct fscache_cookie *parent,         
        const struct fscache_cookie_def *def,
        void *netfs_data)
{       
        // def = &nfs_fscache_super_index_def
        if (fscache_cookie_valid(parent))
                return __fscache_acquire_cookie(parent, def, netfs_data);
        else
                return NULL;
}       

#define fscache_cookie_valid(cookie) (cookie)

/*
 * request a cookie to represent an object (index, datafile, xattr, etc)
 * - parent specifies the parent object
 *   - the top level index cookie for each netfs is stored in the fscache_netfs
 *     struct upon registration
 * - def points to the definition
 * - the netfs_data will be passed to the functions pointed to in *def
 * - all attached caches will be searched to see if they contain this object
 * - index objects aren't stored on disk until there's a dependent file that
 *   needs storing
 * - other objects are stored in a selected cache immediately, and all the
 *   indices forming the path to it are instantiated if necessary
 * - we never let on to the netfs about errors
 *   - we may set a negative cookie pointer, but that's okay
 */
struct fscache_cookie *__fscache_acquire_cookie(
        struct fscache_cookie *parent,
        const struct fscache_cookie_def *def,
        void *netfs_data)
{
        struct fscache_cookie *cookie;

        BUG_ON(!def);

        _enter("{%s},{%s},%p",
               parent ? (char *) parent->def->name : "<no-parent>",
               def->name, netfs_data);

        fscache_stat(&fscache_n_acquires);

        /* if there's no parent cookie, then we don't create one here either */
        if (!parent) {
                fscache_stat(&fscache_n_acquires_null);
                _leave(" [no parent]");
                return NULL;
        }

        /* validate the definition */
        BUG_ON(!def->get_key);
        BUG_ON(!def->name[0]);

        BUG_ON(def->type == FSCACHE_COOKIE_TYPE_INDEX &&
               parent->def->type != FSCACHE_COOKIE_TYPE_INDEX);

        /* allocate and initialise a cookie */
        cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
        // request a cookie
        // 创建一个 cookie to represent a cacahe object

        atomic_set(&cookie->usage, 1);
        atomic_set(&cookie->n_children, 0);

        atomic_inc(&parent->usage);
        atomic_inc(&parent->n_children);

        cookie->def             = def;
        // struct fscache_cookie 结构中 const struct fscache_cookie_def *def;           /* definition */  

        cookie->parent          = parent;
        // struct fscache_cookie           *parent;        /* parent of this entry */`

        cookie->netfs_data      = netfs_data;
        cookie->flags           = 0;

        /* radix tree insertion won't use the preallocation pool unless it's
         * told it may not wait */
        INIT_RADIX_TREE(&cookie->stores, GFP_NOFS & ~__GFP_WAIT);

        switch (cookie->def->type) {
        case FSCACHE_COOKIE_TYPE_INDEX:
                fscache_stat(&fscache_n_cookie_index);
                break;
        case FSCACHE_COOKIE_TYPE_DATAFILE:
                fscache_stat(&fscache_n_cookie_data);
                break;
        default:
                fscache_stat(&fscache_n_cookie_special);
                break;
        }

        /* if the object is an index then we need do nothing more here - we
         * create indices on disk when we need them as an index may exist in
         * multiple caches */
        if (cookie->def->type != FSCACHE_COOKIE_TYPE_INDEX) {
                if (fscache_acquire_non_index_cookie(cookie) < 0) {
                        atomic_dec(&parent->n_children);
                        __fscache_cookie_put(cookie);
                        fscache_stat(&fscache_n_acquires_nobufs);
                        _leave(" = NULL");
                        return NULL;
                }
        }

        fscache_stat(&fscache_n_acquires_ok);
        _leave(" = %p", cookie);
        return cookie;
}

/*
 * get an NFS2/NFS3 root dentry from the root filehandle
 */
struct dentry *nfs_get_root(struct super_block *sb, struct nfs_fh *mntfh)
{
        struct nfs_server *server = NFS_SB(sb);
        struct nfs_fsinfo fsinfo;
        struct dentry *ret;
        struct inode *inode;
        int error;

        /* get the actual root for this mount */
        fsinfo.fattr = nfs_alloc_fattr();
        if (fsinfo.fattr == NULL)
                return ERR_PTR(-ENOMEM);

        error = server->nfs_client->rpc_ops->getroot(server, mntfh, &fsinfo);
        if (error < 0) {
                dprintk("nfs_get_root: getattr error = %d\n", -error);
                ret = ERR_PTR(error);
                goto out;
        }

        inode = nfs_fhget(sb, mntfh, fsinfo.fattr);
        if (IS_ERR(inode)) {
                dprintk("nfs_get_root: get root inode failed\n");
                ret = ERR_CAST(inode);
                goto out;
        }

        error = nfs_superblock_set_dummy_root(sb, inode);
        // Set the superblock root dentry 

        if (error != 0) {
                ret = ERR_PTR(error);
                goto out;
        }

        /* root dentries normally start off anonymous and get spliced in later
         * if the dentry tree reaches them; however if the dentry already
         * exists, we'll pick it up at this point and use it as the root
         */
        ret = d_obtain_alias(inode);
        if (IS_ERR(ret)) {
                dprintk("nfs_get_root: get root dentry failed\n");
                goto out;
        }

        security_d_instantiate(ret, inode);

        if (ret->d_op == NULL)
                ret->d_op = server->nfs_client->rpc_ops->dentry_ops;
out:
        nfs_free_fattr(fsinfo.fattr);
        return ret;
}

/*
 * This is our front-end to iget that looks up inodes by file handle
 * instead of inode number.
 */
struct inode *
nfs_fhget(struct super_block *sb, struct nfs_fh *fh, struct nfs_fattr *fattr)
{       
        struct nfs_find_desc desc = {
                .fh     = fh,
                .fattr  = fattr
        }; 
        struct inode *inode = ERR_PTR(-ENOENT);
        unsigned long hash;
                
        if (((fattr->valid & NFS_ATTR_FATTR_FILEID) == 0) &&
            !nfs_attr_use_mounted_on_fileid(fattr))
                goto out_no_inode;
        if ((fattr->valid & NFS_ATTR_FATTR_TYPE) == 0)
                goto out_no_inode;
                
        hash = nfs_fattr_to_ino_t(fattr);
        
        inode = iget5_locked(sb, hash, nfs_find_actor, nfs_init_locked, &desc);
        // 首先在 inode_hashtable 中查找是否有相应 inode,如果没有则创建 struct nfs_inode 结构中内嵌 struct inode vfs_inode  

        if (inode == NULL) {
                inode = ERR_PTR(-ENOMEM);
                goto out_no_inode;
        }       

        if (inode->i_state & I_NEW) {
                struct nfs_inode *nfsi = NFS_I(inode);
                unsigned long now = jiffies;

                /* We set i_ino for the few things that still rely on it,
                 * such as stat(2) */
                inode->i_ino = hash;

                /* We can't support update_atime(), since the server will reset it */
                inode->i_flags |= S_NOATIME|S_NOCMTIME;
                inode->i_mode = fattr->mode;
                if ((fattr->valid & NFS_ATTR_FATTR_MODE) == 0
                                && nfs_server_capable(inode, NFS_CAP_MODE))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_ACCESS
                                | NFS_INO_INVALID_ACL;
                /* Why so? Because we want revalidate for devices/FIFOs, and
                 * that's precisely what we have in nfs_file_inode_operations.
                 */
                inode->i_op = NFS_SB(sb)->nfs_client->rpc_ops->file_inode_ops;
                if (S_ISREG(inode->i_mode)) {
                        inode->i_fop = &nfs_file_operations;
                        inode->i_data.a_ops = &nfs_file_aops;
			// struct inode 结构中 struct address_space i_data 结构 页高速缓存
                        inode->i_data.backing_dev_info = &NFS_SB(sb)->backing_dev_info;
                } else if (S_ISDIR(inode->i_mode)) {
                        inode->i_op = NFS_SB(sb)->nfs_client->rpc_ops->dir_inode_ops;
                        inode->i_fop = &nfs_dir_operations;
                        set_ext_aops(&inode->i_data, &nfs_dir_aops);
                        if (nfs_server_capable(inode, NFS_CAP_READDIRPLUS))
                                set_bit(NFS_INO_ADVISE_RDPLUS, &NFS_I(inode)->flags);
                        /* Deal with crossing mountpoints */
                        if ((fattr->valid & NFS_ATTR_FATTR_FSID)
                                        && !nfs_fsid_equal(&NFS_SB(sb)->fsid, &fattr->fsid)) {
                                if (fattr->valid & NFS_ATTR_FATTR_V4_REFERRAL)
                                        inode->i_op = &nfs_referral_inode_operations;
                                else
                                        inode->i_op = &nfs_mountpoint_inode_operations;
                                inode->i_fop = NULL;
                                inode->i_flags |= S_AUTOMOUNT;
                        }
                } else if (S_ISLNK(inode->i_mode))
                        inode->i_op = &nfs_symlink_inode_operations;
                else
                        init_special_inode(inode, inode->i_mode, fattr->rdev);

                memset(&inode->i_atime, 0, sizeof(inode->i_atime));
                memset(&inode->i_mtime, 0, sizeof(inode->i_mtime));
                memset(&inode->i_ctime, 0, sizeof(inode->i_ctime));
                nfsi->change_attr = 0;
                inode->i_size = 0;
                inode->i_nlink = 0;
                inode->i_uid = -2;
                inode->i_gid = -2;
                inode->i_blocks = 0;
                memset(nfsi->cookieverf, 0, sizeof(nfsi->cookieverf));

                nfsi->read_cache_jiffies = fattr->time_start;
                nfsi->attr_gencount = fattr->gencount;
                if (fattr->valid & NFS_ATTR_FATTR_ATIME)
                        inode->i_atime = fattr->atime;
                else if (nfs_server_capable(inode, NFS_CAP_ATIME))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR;
                if (fattr->valid & NFS_ATTR_FATTR_MTIME)
                        inode->i_mtime = fattr->mtime;
                else if (nfs_server_capable(inode, NFS_CAP_MTIME))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_DATA;
                if (fattr->valid & NFS_ATTR_FATTR_CTIME)
                        inode->i_ctime = fattr->ctime;
                else if (nfs_server_capable(inode, NFS_CAP_CTIME))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_ACCESS
                                | NFS_INO_INVALID_ACL;
                if (fattr->valid & NFS_ATTR_FATTR_CHANGE)
                        nfsi->change_attr = fattr->change_attr;
                else if (nfs_server_capable(inode, NFS_CAP_CHANGE_ATTR))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_DATA;
                if (fattr->valid & NFS_ATTR_FATTR_SIZE)
                        inode->i_size = nfs_size_to_loff_t(fattr->size);
                else
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_DATA
                                | NFS_INO_REVAL_PAGECACHE;
                if (fattr->valid & NFS_ATTR_FATTR_NLINK)
                        inode->i_nlink = fattr->nlink;
                else if (nfs_server_capable(inode, NFS_CAP_NLINK))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR;
                if (fattr->valid & NFS_ATTR_FATTR_OWNER)
                        inode->i_uid = fattr->uid;
                else if (nfs_server_capable(inode, NFS_CAP_OWNER))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_ACCESS
                                | NFS_INO_INVALID_ACL;
                if (fattr->valid & NFS_ATTR_FATTR_GROUP)
                        inode->i_gid = fattr->gid;
                else if (nfs_server_capable(inode, NFS_CAP_OWNER_GROUP))
                        nfsi->cache_validity |= NFS_INO_INVALID_ATTR
                                | NFS_INO_INVALID_ACCESS
                                | NFS_INO_INVALID_ACL;
                if (fattr->valid & NFS_ATTR_FATTR_BLOCKS_USED)
                        inode->i_blocks = fattr->du.nfs2.blocks;
                if (fattr->valid & NFS_ATTR_FATTR_SPACE_USED) {
                        /*
                         * report the blocks in 512byte units
                         */
                        inode->i_blocks = nfs_calc_block_size(fattr->du.nfs3.used);
                }
                nfsi->attrtimeo = NFS_MINATTRTIMEO(inode);
                nfsi->attrtimeo_timestamp = now;
                nfsi->access_cache = RB_ROOT;

                nfs_fscache_init_inode_cookie(inode);

                unlock_new_inode(inode);
        } else
                nfs_refresh_inode(inode, fattr);
        dprintk("NFS: nfs_fhget(%s/%Ld ct=%d)\n",
                inode->i_sb->s_id,
                (long long)NFS_FILEID(inode),
                atomic_read(&inode->i_count));

out:
        return inode;

out_no_inode:
        dprintk("nfs_fhget: iget failed with error %ld\n", PTR_ERR(inode));
        goto out;
}


const struct address_space_operations nfs_file_aops = {
        .readpage = nfs_readpage,
        .readpages = nfs_readpages,
        .set_page_dirty = __set_page_dirty_nobuffers,
        .writepage = nfs_writepage,
        .writepages = nfs_writepages,
        .write_begin = nfs_write_begin,
        .write_end = nfs_write_end,
        .invalidatepage = nfs_invalidate_page,
        .releasepage = nfs_release_page,
        .direct_IO = nfs_direct_IO,
        .migratepage = nfs_migrate_page,
        .launder_page = nfs_launder_page,
        .error_remove_page = generic_error_remove_page,
};


/*
 * Set the superblock root dentry.
 * Note that this function frees the inode in case of error.
 */
static int nfs_superblock_set_dummy_root(struct super_block *sb, struct inode *inode)
{
        /* The mntroot acts as the dummy root dentry for this superblock */
        if (sb->s_root == NULL) {
                sb->s_root = d_alloc_root(inode);
                // 创建 dentry 结构 给跟目录

                if (sb->s_root == NULL) {
                        iput(inode);
                        return -ENOMEM;
                }
                /* Circumvent igrab(): we know the inode is not being freed */
                atomic_inc(&inode->i_count);
                /*
                 * Ensure that this dentry is invisible to d_find_alias().
                 * Otherwise, it may be spliced into the tree by
                 * d_materialise_unique if a parent directory from the same
                 * filesystem gets mounted at a later time.
                 * This again causes shrink_dcache_for_umount_subtree() to
                 * Oops, since the test for IS_ROOT() will fail.
                 */
                spin_lock(&dcache_lock);
                list_del_init(&sb->s_root->d_alias);
                spin_unlock(&dcache_lock);
        }
        return 0;
}

---------------------------------------- 8< ---------------------------------------------------- 
fs/open.c

SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, int, mode)
{      
        long ret;

        if (force_o_largefile())
                flags |= O_LARGEFILE;

        ret = do_sys_open(AT_FDCWD, filename, flags, mode);
        /* avoid REGPARM breakage on x86: */
        asmlinkage_protect(3, ret, filename, flags, mode);
        return ret;
}

do_filp_open()
  -> 


do_lookup()
  -> d_alloc()
     // 为要打开的文件创建目录项对象
       -> dir->i_op->lookup()
	// 创建要打开文件的 inode


---------------------------------------- 8< ---------------------------------------------------- 
fs/read_write.c 

SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
{
        struct file *file;
        ssize_t ret = -EBADF;
        int fput_needed;

        file = fget_light(fd, &fput_needed);
        if (file) {
                loff_t pos = file_pos_read(file);
                ret = vfs_read(file, buf, count, &pos);
                file_pos_write(file, pos);
                fput_light(file, fput_needed);
        }

        return ret;
}

vfs_read()
  -> file->f_op->read()
     do_sync_read()
       -> filp->f_op->aio_read()  
          nfs_file_read()
 

static ssize_t
nfs_file_read(struct kiocb *iocb, const struct iovec *iov,
                unsigned long nr_segs, loff_t pos)
{
        struct dentry * dentry = iocb->ki_filp->f_path.dentry;
        struct inode * inode = dentry->d_inode;
        ssize_t result;
        size_t count = iov_length(iov, nr_segs);

        if (iocb->ki_filp->f_flags & O_DIRECT)
                return nfs_file_direct_read(iocb, iov, nr_segs, pos);

        dprintk("NFS: read(%s/%s, %lu@%lu)\n",
                dentry->d_parent->d_name.name, dentry->d_name.name,
                (unsigned long) count, (unsigned long) pos);

        result = nfs_revalidate_mapping(inode, iocb->ki_filp->f_mapping);
        nfs_add_stats(inode, NFSIOS_NORMALREADBYTES, count);
        if (!result)
                result = generic_file_aio_read(iocb, iov, nr_segs, pos);
        return result;
}

generic_file_aio_read()
  -> do_generic_file_read() 
     // 从磁盘读入所请求的页并把它们拷贝到用户态缓冲区
       -> mapping->a_ops->readpage(filp, page)
          nfs_readpage()


/**
 * do_generic_file_read - generic file read routine
 * @filp:       the file to read
 * @ppos:       current file position
 * @desc:       read_descriptor
 * @actor:      read method
 *
 * This is a generic file read routine, and uses the
 * mapping->a_ops->readpage() function for the actual low-level stuff.
 *
 * This is really ugly. But the goto's actually try to clarify some
 * of the logic when it comes to error handling etc.
 */
static void do_generic_file_read(struct file *filp, loff_t *ppos,
                read_descriptor_t *desc, read_actor_t actor)
{
        struct address_space *mapping = filp->f_mapping;
        struct inode *inode = mapping->host;
        struct file_ra_state *ra = &filp->f_ra;
        pgoff_t index;
        pgoff_t last_index;
        pgoff_t prev_index;
        unsigned long offset;      /* offset into pagecache page */
        unsigned int prev_offset;
        int error;

        index = *ppos >> PAGE_CACHE_SHIFT;
        prev_index = ra->prev_pos >> PAGE_CACHE_SHIFT;
        prev_offset = ra->prev_pos & (PAGE_CACHE_SIZE-1);
        last_index = (*ppos + desc->count + PAGE_CACHE_SIZE-1) >> PAGE_CACHE_SHIFT;
        offset = *ppos & ~PAGE_CACHE_MASK;

        for (;;) {
                struct page *page;
                pgoff_t end_index;
                loff_t isize;
                unsigned long nr, ret;

                cond_resched();
		// 检查当前进程的标志 TIF_NEED_RESCHED ,若置位则调用函数 schedule()
find_page:
                page = find_get_page(mapping, index);
                // 从当前文件页高速缓存中查找页面

                if (!page) {
                        page_cache_sync_readahead(mapping,
                                        ra, filp,
                                        index, last_index - index);
                        page = find_get_page(mapping, index);
                        if (unlikely(page == NULL))
                                goto no_cached_page;
			// 如果文件的 page cache 中没有相关缓存 则创建一个新页然后检查 fscache 中是否缓存了此文件，如果缓存则将数据写到此页中，否则将创建缓存。
                }
                if (PageReadahead(page)) {
                        page_cache_async_readahead(mapping,
                                        ra, filp, page,
                                        index, last_index - index);
                }
                if (!PageUptodate(page)) {
			// 若 PG_uptodate 标志置位表示页所存数据为最新的
                        if (inode->i_blkbits == PAGE_CACHE_SHIFT ||
                                        !mapping->a_ops->is_partially_uptodate)
                                goto page_not_up_to_date;
                        if (!trylock_page(page))
                                goto page_not_up_to_date;
                        /* Did it get truncated before we got the lock? */
                        if (!page->mapping)
                                goto page_not_up_to_date_locked;
                        if (!mapping->a_ops->is_partially_uptodate(page,
                                                                desc, offset))
                                goto page_not_up_to_date_locked;
                        unlock_page(page);
                }
page_ok:
                /*
                 * i_size must be checked after we know the page is Uptodate.
                 *
                 * Checking i_size after the check allows us to calculate
                 * the correct value for "nr", which means the zero-filled
                 * part of the page is not copied back to userspace (unless
                 * another truncate extends the file - this is desired though).
                 */

                isize = i_size_read(inode);
                end_index = (isize - 1) >> PAGE_CACHE_SHIFT;
                if (unlikely(!isize || index > end_index)) {
                        page_cache_release(page);
                        goto out;
                }

                /* nr is the maximum number of bytes to copy from this page */
                nr = PAGE_CACHE_SIZE;
                if (index == end_index) {
                        nr = ((isize - 1) & ~PAGE_CACHE_MASK) + 1;
                        if (nr <= offset) {
                                page_cache_release(page);
                                goto out;
                        }
                }
                nr = nr - offset;

                /* If users can be writing to this page using arbitrary
                 * virtual addresses, take care about potential aliasing
                 * before reading the page on the kernel side.
                 */
                if (mapping_writably_mapped(mapping))
                        flush_dcache_page(page);

                /*
                 * When a sequential read accesses a page several times,
                 * only mark it as accessed the first time.
                 */
                if (prev_index != index || offset != prev_offset)
                        mark_page_accessed(page);
                prev_index = index;

                /*
                 * Ok, we have the page, and it's up-to-date, so
                 * now we can copy it to user space...
                 *
                 * The actor routine returns how many bytes were actually used..
                 * NOTE! This may not be the same as how much of a user buffer
                 * we filled up (we may be padding etc), so we can only update
                 * "pos" here (the actor routine has to update the user buffer
                 * pointers and the remaining count).
                 */
                ret = actor(desc, page, offset, nr);
		// 调用 file_read_actor 函数把页中数据拷贝到用户态缓冲区

                offset += ret;
                index += offset >> PAGE_CACHE_SHIFT;
                offset &= ~PAGE_CACHE_MASK;
                prev_offset = offset;

                page_cache_release(page);
                if (ret == nr && desc->count)
                        continue;
                goto out;
		// over

page_not_up_to_date:
                /* Get exclusive access to the page ... */
                error = lock_page_killable(page);
                if (unlikely(error))
                        goto readpage_error;

page_not_up_to_date_locked:
                /* Did it get truncated before we got the lock? */
                if (!page->mapping) {
                        unlock_page(page);
                        page_cache_release(page);
                        continue;
                }

                /* Did somebody else fill it already? */
                if (PageUptodate(page)) {
                        unlock_page(page);
                        goto page_ok;
                }

readpage:
                /*
                 * A previous I/O error may have been due to temporary
                 * failures, eg. multipath errors.
                 * PG_error will be set again if readpage fails.
                 */
                ClearPageError(page);
                /* Start the actual read. The read will unlock the page. */
                error = mapping->a_ops->readpage(filp, page);
		// invoke the nfs_readpage() 将文件内容从 fscache 读入到 cached pages 中. 

                if (unlikely(error)) {
                        if (error == AOP_TRUNCATED_PAGE) {
                                page_cache_release(page);
                                goto find_page;
                        }
                        goto readpage_error;
                }

                if (!PageUptodate(page)) {
                        error = lock_page_killable(page);
                        if (unlikely(error))
                                goto readpage_error;
                        if (!PageUptodate(page)) {
                                if (page->mapping == NULL) {
                                        /*
                                         * invalidate_inode_pages got it
                                         */
                                        unlock_page(page);
                                        page_cache_release(page);
                                        goto find_page;
                                }
                                unlock_page(page);
                                shrink_readahead_size_eio(filp, ra);
                                error = -EIO;
                                goto readpage_error;
                        }
                        unlock_page(page);
                }

                goto page_ok;

readpage_error:
                /* UHHUH! A synchronous read error occurred. Report it */
                desc->error = error;
                page_cache_release(page);
                goto out;

no_cached_page:
                /*
                 * Ok, it wasn't cached, so we need to create a new
                 * page..
                 */
                page = page_cache_alloc_cold(mapping);
		// 创建一个 page

                if (!page) {
                        desc->error = -ENOMEM;
                        goto out;
                }
                error = add_to_page_cache_lru(page, mapping,
                                                index, GFP_KERNEL);
                if (error) {
                        page_cache_release(page);
                        if (error == -EEXIST)
                                goto find_page;
                        desc->error = error;
                        goto out;
                }
                goto readpage;
        }

out:
        ra->prev_pos = prev_index;
        ra->prev_pos <<= PAGE_CACHE_SHIFT;
        ra->prev_pos |= prev_offset;

        *ppos = ((loff_t)index << PAGE_CACHE_SHIFT) + offset;
        file_accessed(filp);
}



/*
 * Read a page over NFS.
 * We read the page synchronously in the following case:
 *  -   The error flag is set for this page. This happens only when a
 *      previous async read operation failed.
 */
int nfs_readpage(struct file *file, struct page *page)
{
        struct nfs_open_context *ctx;
        struct inode *inode = page->mapping->host;
        int             error;

        dprintk("NFS: nfs_readpage (%p %ld@%lu)\n",
                page, PAGE_CACHE_SIZE, page->index);
        nfs_inc_stats(inode, NFSIOS_VFSREADPAGE);
        nfs_add_stats(inode, NFSIOS_READPAGES, 1);

        /*
         * Try to flush any pending writes to the file..
         *      
         * NOTE! Because we own the page lock, there cannot
         * be any new pending writes generated at this point
         * for this page (other pages can be written to).
         */     
        error = nfs_wb_page(inode, page);
        if (error)              
                goto out_unlock;
        if (PageUptodate(page))
                goto out_unlock;
                
        error = -ESTALE;
        if (NFS_STALE(inode))
                goto out_unlock;

        if (file == NULL) {
                error = -EBADF;
                ctx = nfs_find_open_context(inode, NULL, FMODE_READ);
                if (ctx == NULL)
                        goto out_unlock;
        } else
                ctx = get_nfs_open_context(nfs_file_open_context(file));
                // filp->private_data

        if (!IS_SYNC(inode)) {
                error = nfs_readpage_from_fscache(ctx, inode, page);
                if (error == 0)
                        goto out;
        }

        error = nfs_readpage_async(ctx, inode, page);

out:
        put_nfs_open_context(ctx);
        return error;
out_unlock:
        unlock_page(page);
        return error;
}

/*
 * Write back all requests on one page - we do this before reading it.
 */             
int nfs_wb_page(struct inode *inode, struct page *page)
{       
        loff_t range_start = page_offset(page);
        loff_t range_end = range_start + (loff_t)(PAGE_CACHE_SIZE - 1);
        struct writeback_control wbc = {
                .sync_mode = WB_SYNC_ALL,
                .nr_to_write = 0,
                .range_start = range_start,
                .range_end = range_end,
        };
        int ret;
        
        for (;;) {
                wait_on_page_writeback(page);
                if (clear_page_dirty_for_io(page)) {
                        ret = nfs_writepage_locked(page, &wbc);
                        if (ret < 0)
                                goto out_error;
                        continue;
                }
                if (!PagePrivate(page))
                        break;
                ret = nfs_commit_inode(inode, FLUSH_SYNC);
                if (ret < 0)
                        goto out_error;
        }
        return 0;
out_error:
        return ret;
}

/*              
 * Retrieve a page from an inode data storage object.
 */     
static inline int nfs_readpage_from_fscache(struct nfs_open_context *ctx,
                                            struct inode *inode,
                                            struct page *page)
{       
        if (NFS_I(inode)->fscache)
                return __nfs_readpage_from_fscache(ctx, inode, page);
        // struct nfs_inode
        return -ENOBUFS;
}

/*
 * nfs fs inode data in memory
 */
struct nfs_inode {

        ......
 
#ifdef CONFIG_NFS_FSCACHE
        struct fscache_cookie   *fscache;
#endif
        struct inode            vfs_inode;

};

/*
 * Retrieve a page from fscache 
 */             
int __nfs_readpage_from_fscache(struct nfs_open_context *ctx,
                                struct inode *inode, struct page *page)
{
        int ret;

        dfprintk(FSCACHE,
                 "NFS: readpage_from_fscache(fsc:%p/p:%p(i:%lx f:%lx)/0x%p)\n",
                 NFS_I(inode)->fscache, page, page->index, page->flags, inode);

        ret = fscache_read_or_alloc_page(NFS_I(inode)->fscache,
                                         page,
                                         nfs_readpage_from_fscache_complete,
                                         ctx,
                                         GFP_KERNEL);

        switch (ret) {
        case 0: /* read BIO submitted (page in fscache) */
                dfprintk(FSCACHE,
                         "NFS:    readpage_from_fscache: BIO submitted\n");
                nfs_add_fscache_stats(inode, NFSIOS_FSCACHE_PAGES_READ_OK, 1);
                return ret;                  
                                             
        case -ENOBUFS: /* inode not in cache */
        case -ENODATA: /* page not in cache */
                nfs_add_fscache_stats(inode, NFSIOS_FSCACHE_PAGES_READ_FAIL, 1);
                dfprintk(FSCACHE,                   
                         "NFS:    readpage_from_fscache %d\n", ret);
                return 1;

        default:
                dfprintk(FSCACHE, "NFS:    readpage_from_fscache %d\n", ret);
                nfs_add_fscache_stats(inode, NFSIOS_FSCACHE_PAGES_READ_FAIL, 1);
        }
        return ret;
}

/**
 * fscache_read_or_alloc_page - Read a page from the cache or allocate a block
 * in which to store it
 * @cookie: The cookie representing the cache object
 * @page: The netfs page to fill if possible
 * @end_io_func: The callback to invoke when and if the page is filled
 * @context: An arbitrary piece of data to pass on to end_io_func()
 * @gfp: The conditions under which memory allocation should be made
 *
 * Read a page from the cache, or if that's not possible make a potential
 * one-block reservation in the cache into which the page may be stored once
 * fetched from the server.
 *
 * If the page is not backed by the cache object, or if it there's some reason
 * it can't be, -ENOBUFS will be returned and nothing more will be done for
 * that page.
 *
 * Else, if that page is backed by the cache, a read will be initiated directly
 * to the netfs's page and 0 will be returned by this function.  The
 * end_io_func() callback will be invoked when the operation terminates on a
 * completion or failure.  Note that the callback may be invoked before the
 * return.
 *
 * Else, if the page is unbacked, -ENODATA is returned and a block may have
 * been allocated in the cache.
 *
 * See Documentation/filesystems/caching/netfs-api.txt for a complete
 * description.
 */
static inline
int fscache_read_or_alloc_page(struct fscache_cookie *cookie,
                               struct page *page,
                               fscache_rw_complete_t end_io_func,
                               void *context,
                               gfp_t gfp)
{
        if (fscache_cookie_valid(cookie))
                return __fscache_read_or_alloc_page(cookie, page, end_io_func,
                                                    context, gfp);
        else
                return -ENOBUFS;
	        // If the cookie indicates the inode is not cached. return -ENOBUFS
}

/*
 * read a page from the cache or allocate a block in which to store it
 * - we return:
 *   -ENOMEM    - out of memory, nothing done
 *   -ERESTARTSYS - interrupted
 *   -ENOBUFS   - no backing object available in which to cache the block
 *   -ENODATA   - no data available in the backing object for this block
 *   0          - dispatched a read - it'll call end_io_func() when finished
 */                            
int __fscache_read_or_alloc_page(struct fscache_cookie *cookie,
                                 struct page *page,
                                 fscache_rw_complete_t end_io_func,
                                 void *context,     
                                 gfp_t gfp)
{               
        struct fscache_retrieval *op;
        struct fscache_object *object;
        int ret;

        _enter("%p,%p,,,", cookie, page);

        fscache_stat(&fscache_n_retrievals);

        if (hlist_empty(&cookie->backing_objects))
                goto nobufs;

        ASSERTCMP(cookie->def->type, !=, FSCACHE_COOKIE_TYPE_INDEX);
        ASSERTCMP(page, !=, NULL);

        if (fscache_wait_for_deferred_lookup(cookie) < 0)
                return -ERESTARTSYS;

        op = fscache_alloc_retrieval(page->mapping, end_io_func, context);
        if (!op) {
                _leave(" = -ENOMEM");
                return -ENOMEM;
        }
        fscache_set_op_name(&op->op, "RetrRA1");

        spin_lock(&cookie->lock);

        if (hlist_empty(&cookie->backing_objects))
                goto nobufs_unlock;
        object = hlist_entry(cookie->backing_objects.first,
                             struct fscache_object, cookie_link);

        ASSERTCMP(object->state, >, FSCACHE_OBJECT_LOOKING_UP);

        atomic_inc(&object->n_reads);
        set_bit(FSCACHE_OP_DEC_READ_CNT, &op->op.flags);

        if (fscache_submit_op(object, &op->op) < 0)
                goto nobufs_unlock;
        spin_unlock(&cookie->lock);

        fscache_stat(&fscache_n_retrieval_ops);

        /* pin the netfs read context in case we need to do the actual netfs
         * read because we've encountered a cache read failure */
        fscache_get_context(object->cookie, op->context);

        /* we wait for the operation to become active, and then process it
         * *here*, in this thread, and not in the thread pool */
        ret = fscache_wait_for_retrieval_activation(
                object, op,
                __fscache_stat(&fscache_n_retrieval_op_waits),
                __fscache_stat(&fscache_n_retrievals_object_dead));
        if (ret < 0)
                goto error;

        /* ask the cache to honour the operation */
        if (test_bit(FSCACHE_COOKIE_NO_DATA_YET, &object->cookie->flags)) {
                fscache_stat(&fscache_n_cop_allocate_page);
                ret = object->cache->ops->allocate_page(op, page, gfp);
                fscache_stat_d(&fscache_n_cop_allocate_page);
                if (ret == 0)
                        ret = -ENODATA;
        } else {
                fscache_stat(&fscache_n_cop_read_or_alloc_page);
                ret = object->cache->ops->read_or_alloc_page(op, page, gfp);
		// read a netfs page from the cache.
		// submit a request to read the data from the cache's backing device directly into the page specified

                fscache_stat_d(&fscache_n_cop_read_or_alloc_page);
        }

error:
        if (ret == -ENOMEM)
                fscache_stat(&fscache_n_retrievals_nomem);
        else if (ret == -ERESTARTSYS)
                fscache_stat(&fscache_n_retrievals_intr);
        else if (ret == -ENODATA)
                fscache_stat(&fscache_n_retrievals_nodata);
        else if (ret < 0)
                fscache_stat(&fscache_n_retrievals_nobufs);
        else
                fscache_stat(&fscache_n_retrievals_ok);

        fscache_put_retrieval(op);
        _leave(" = %d", ret);
        return ret;

nobufs_unlock:
        spin_unlock(&cookie->lock);
        kfree(op);
nobufs:
        fscache_stat(&fscache_n_retrievals_nobufs);
        _leave(" = -ENOBUFS");
        return -ENOBUFS;
}

/*
 * data read operation
 */
struct fscache_retrieval {
        struct fscache_operation op;
        struct address_space    *mapping;       /* netfs pages */
        fscache_rw_complete_t   end_io_func;    /* function to call on I/O completion */
        void                    *context;       /* netfs read context (pinned) */
        struct list_head        to_do;          /* list of things to be done by the backend */
        unsigned long           start_time;     /* time at which retrieval started */
};                               


/*
 * allocate a retrieval op
 */
static struct fscache_retrieval *fscache_alloc_retrieval(
        struct address_space *mapping,
        fscache_rw_complete_t end_io_func,
        void *context)
{
        struct fscache_retrieval *op;

        /* allocate a retrieval operation and attempt to submit it */
        op = kzalloc(sizeof(*op), GFP_NOIO);
        if (!op) {
                fscache_stat(&fscache_n_retrievals_nomem);
                return NULL;
        }

        fscache_operation_init(&op->op, fscache_release_retrieval_op);
        op->op.flags    = FSCACHE_OP_MYTHREAD | (1 << FSCACHE_OP_WAITING);
        op->mapping     = mapping;
        op->end_io_func = end_io_func;
        op->context     = context;
        op->start_time  = jiffies;
        INIT_WORK(&op->op.fast_work, fscache_retrieval_work);
        INIT_LIST_HEAD(&op->to_do);
        fscache_set_op_name(&op->op, "Retr");
        return op;
}

// When the read is complete,end_io_func() -> nfs_readpage_from_fscache_complete() will be inovked.

/*
 * Handle completion of a page being read from the cache.
 * - Called in process (keventd) context.
 */
static void nfs_readpage_from_fscache_complete(struct page *page,
                                               void *context,
                                               int error)
{
        dfprintk(FSCACHE,
                 "NFS: readpage_from_fscache_complete (0x%p/0x%p/%d)\n",
                 page, context, error);

        /* if the read completes with an error, we just unlock the page and let
         * the VM reissue the readpage */
        if (!error) {
                SetPageUptodate(page);
                unlock_page(page);
        } else {
                error = nfs_readpage_async(context, page->mapping->host, page);
		// 猜测从server 中读取文件内容 netfs -> cached pages -> cached files
                if (error)
                        unlock_page(page);
        }
}

int nfs_readpage_async(struct nfs_open_context *ctx, struct inode *inode,
                       struct page *page)
{
        struct nfs_page *new;
        unsigned int len;
        struct nfs_pageio_descriptor pgio;
                                               
        len = nfs_page_length(page);           
        if (len == 0)
                return nfs_return_empty_page(page);
        new = nfs_create_request(ctx, inode, page, 0, len);
        if (IS_ERR(new)) {
                unlock_page(page);
                return PTR_ERR(new);
        }
        if (len < PAGE_CACHE_SIZE)
                zero_user_segment(page, len, PAGE_CACHE_SIZE);
                
        nfs_pageio_init(&pgio, inode, NULL, 0, 0);
        nfs_list_add_request(new, &pgio.pg_list);
        pgio.pg_count = len;
                        
        if (NFS_SERVER(inode)->rsize < PAGE_CACHE_SIZE)
                nfs_pagein_multi(&pgio);
        else
                nfs_pagein_one(&pgio);
        return 0;
}


---------------------------------------- 8< ---------------------------------------------------- 
fs/read_write.c 

SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
                size_t, count)
{      
        struct file *file;
        ssize_t ret = -EBADF;
        int fput_needed;

        file = fget_light(fd, &fput_needed);
        if (file) {
                loff_t pos = file_pos_read(file);
                ret = vfs_write(file, buf, count, &pos);
                file_pos_write(file, pos);
                fput_light(file, fput_needed);
        }
       
        return ret;
}


const struct file_operations nfs_file_operations = {
        .llseek         = nfs_file_llseek,
        .read           = do_sync_read,
        .write          = do_sync_write,
        .aio_read       = nfs_file_read,
        .aio_write      = nfs_file_write,
        .mmap           = nfs_file_mmap,
        .open           = nfs_file_open,
        .flush          = nfs_file_flush,
        .release        = nfs_file_release,
        .fsync          = nfs_file_fsync,
        .lock           = nfs_lock,
        .flock          = nfs_flock,
        .splice_read    = nfs_file_splice_read,
        .splice_write   = nfs_file_splice_write,
        .check_flags    = nfs_check_flags,
        .setlease       = nfs_setlease,
};


vfs_write()
 -> file->f_op->write()
    do_sync_write()
      -> filp->f_op->aio_write()
         nfs_file_write()
           -> generic_file_aio_write()
              // 将文件写入页高速缓存
                -> __generic_file_aio_write()
                    -> generic_file_buffered_write()

ssize_t
generic_file_buffered_write(struct kiocb *iocb, const struct iovec *iov,
                unsigned long nr_segs, loff_t pos, loff_t *ppos,
                size_t count, ssize_t written)
{
        struct file *file = iocb->ki_filp;
        struct address_space *mapping = file->f_mapping;
        // 指向要写入文件的 indode 结构的 i_data(struct address_space)
        // 其中的 i_data a_ops = &nfs_file_aops

        ssize_t status;
        struct iov_iter i;

        iov_iter_init(&i, iov, nr_segs, count, written);
        status = generic_perform_write(file, &i, pos);

        if (likely(status >= 0)) {
                written += status;
                *ppos = pos + status;
        }

        /*
         * If we get here for O_DIRECT writes then we must have fallen through
         * to buffered writes (block instantiation inside i_size).  So we sync
         * the file data here, to try to honour O_DIRECT expectations.
         */
        if (unlikely(file->f_flags & O_DIRECT) && written)
                status = filemap_write_and_wait_range(mapping,
                                        pos, pos + written - 1);

        return written ? written : status;
}

generic_perform_write()
  -> a_ops->write_begin()
      -> nfs_write_begin()  


do_writepages()
 -> nfs_writepage()

/*
 * This does the "real" work of the write. We must allocate and lock the
 * page to be sent back to the generic routine, which then copies the
 * data from user space.
 *
 * If the writer ends up delaying the write, the writer needs to
 * increment the page use counts until he is done with the page.
 */
static int nfs_write_begin(struct file *file, struct address_space *mapping,
                        loff_t pos, unsigned len, unsigned flags,
                        struct page **pagep, void **fsdata)
{
        int ret;
        pgoff_t index = pos >> PAGE_CACHE_SHIFT;
        struct page *page;
        int once_thru = 0;

        dfprintk(PAGECACHE, "NFS: write_begin(%s/%s(%ld), %u@%lld)\n",
                file->f_path.dentry->d_parent->d_name.name,
                file->f_path.dentry->d_name.name,
                mapping->host->i_ino, len, (long long) pos);

start:
        /*
         * Prevent starvation issues if someone is doing a consistency
         * sync-to-disk
         */
        ret = wait_on_bit(&NFS_I(mapping->host)->flags, NFS_INO_FLUSHING,
                        nfs_wait_bit_killable, TASK_KILLABLE);
        if (ret)
                return ret;

        page = grab_cache_page_write_begin(mapping, index, flags);
        if (!page)
                return -ENOMEM;
        *pagep = page;

        ret = nfs_flush_incompatible(file, page);
        if (ret) {
                unlock_page(page);
                page_cache_release(page);
        } else if (!once_thru &&
                   nfs_want_read_modify_write(file, page, pos, len)) {
                once_thru = 1;
                ret = nfs_readpage(file, page);
                page_cache_release(page);
                if (!ret)
                        goto start;
        }
        return ret;
}

